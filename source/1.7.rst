千辛万苦训练好模型，上线遇到问题？Paddle 预测库轻松搞定预测部署
===============


有了训练好的模型之后，离最终的服务上线只差一步——预测部署。
Paddle 提供了性能强劲、上手简单的预测库来帮助用户更好地进行预测部署，
使用 Paddle 预测库，用户可以专注于数据处理，而不用担心服务的性能问题。

下面我们一起来实战吧！


1. 模型保存
------------

首先我们需要得到一个预测模型。Paddle 提供内置函数 `save_inference_model` 将训练网络保存为预测模型。

.. code:: python
    
    from paddle import fluid

    place = fluid.CPUPlace()
    executor = fluid.Executor(place)

    image = fluid.data(name="image", shape=[None, 28, 28], dtype="float32")
    label = fluid.data(name="label", shape=[None, 1], dtype="int64")

    feeder = fluid.DataFeeder(feed_list=[image, label], place=place)
    predict = fluid.layers.fc(input=image, size=10, act='softmax')

    loss = fluid.layers.cross_entropy(input=predict, label=label)
    avg_loss = fluid.layers.mean(loss)

    executor.run(fluid.default_startup_program())

    # 保存预测模型
    fluid.io.save_inference_model("model", feed_var_names=["image"],
        target_vars=[predict]. executor=executor)


.. tip::

    `save_inference_model`对训练模型进行剪枝，去除和预测无关部分，得到的模型更加适合预测部署.


2. 预测加载
-----------

有了预测模型之后，就可以使用预测库了。Paddle 提供了 AnalysisConfig 用于管理预测部署的各种设置。

.. code:: python

    from paddle.fluid.core import AnalysisConfig

    # 创建配置对象
    config = AnalysisConfig("./model")



使用 CPU 预测时，若硬件支持，可打开 MKLDNN 优化开关。

.. code:: python

    config.enable_mkldnn()



目前 Paddle 支持 Nvidia GPU 用户使用 GPU 预测。

.. code:: python

    # 在 GPU 0 上初始化 100 MB 显存。这只是一个初始值，实际显存可能会动态变化。
    config.enable_use_gpu(100, 0)


.. tip::

    Paddle 预测还提供了零拷贝的方式，以减少输入输出数据的拷贝次数

    .. code:: python

        # 打开零拷贝。若不需要零拷贝功能，则不用设置如下选项。
        config.switch_use_feed_fetch_ops(False)
        config.switch_specify_input_names(True)


设置好预测的配置后，就可以创建预测器了。


.. code:: python

    from paddle.fluid.core import create_paddle_predictor

    predictor = create_paddle_predictor(config)


.. tip::

    Paddle 预测提供了多项图优化，创建预测器时将会加载预测模型并自动进行图优化，以增强预测性能。


3. 运行预测
------------

创建好预测器后，只需传入数据就可以运行预测了。Paddle预测提供了两种方式进行预测，我们假定输入数据读入到 numpy.ndarray，下面分别介绍两种预测方式的使用。


3.1 零拷贝
~~~~~~~~~~~~
使用零拷贝时, Paddle 预测内部使用 ZeroCopyTensor 管理输入输出

首先将输入数据传入预测器


.. code:: python

    input_names = predictor.get_input_names()
    # 得到输入 ZeroCopyTensor，前面保存的模型只有一个输入图片，多输入下的操作是类似的。
    input_tensor = predictor.get_input_tensor(input_names[0])

    input_tensor.copy_from_cpu(input_data.reshape([1, 28, 28]).astype("float32"))


运行预测


.. code:: python

    predictor.zero_copy_run()


解析预测输出结果


.. code:: python

    ouput_names = predictor.get_output_names()
    # 获取输出 ZeroCopyTensor
    output_tensor = predictor.get_output_tensor(output_names[0])

    # 得到一个 numpy.ndarray 封装的输出数据
    output_data = output_tensor.copy_to_cpu()


3.2 不使用零拷贝
~~~~~~~~~~~
不使用零拷贝方式运行预测时, Paddle 预测使用 PaddleTensor 管理输入和输出.

用 PaddleTensor 传入输入数据


.. code:: python

    from paddle.fluid.core import PaddleTensor
    input_tensor = PaddleTensor(input_data.reshape([1, 28, 28]).astype("float32"))


运行预测并返回输出结果


.. code:: python

    # 获得输出 PaddleTensor
    output_tensor = predictor.run([input_tensor])

    # 将 PaddleTensor 转换为 numpy.ndarray 数据类型
    output_data = output_tensor.as_ndarray()


4. 进阶
-------------

4.1 使用 TensorRT 加速预测
~~~~~~~~~~~~

Paddle 预测集成了 TensorRT 引擎。使用 GPU 预测时，开启 TensorRT 在一些模型上可以提高性能。


.. code:: python

    config.enable_tensorrt_engine(precision_mode=AnalysisConfig.Precision.Float32,
                                  use_calib_mode=True)


4.2 使用Paddle-Lite优化
~~~~~~~~
Paddle-Lite


4.3 在其它语言中使用 Paddle 预测
~~~~~~~

为满足不同用户的需求，Paddle 预测库支持 C++、C、Python、Go 和 R 语言。



.. note::

    Paddle 预测推荐使用 C++ 和 Python 用户接口，这两种语言的接口已经过严格测试和多次的迭代，稳定可靠。

    .. tip::


        `Paddle 预测已支持语言`

        ==========  ======  ======  ======  ======  ======
        语言    C++     Python  C       Go      R 
        ==========  ======  ======  ======  ======  ======
        用户接口         完整    完整    完整    完整    完整
        性能        对齐    对齐    对齐    对齐    待对齐
        ==========  ======  ======  ======  ======  ======

        
